---
title: "Bootstrapping and Confidence"
author: "Xiaochi"
date: "09/01/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(moderndive)
library(infer)
```

## Pennies activity

### What is the average year on US pennies in 2019?

```{r}
pennies_sample
```

```{r}
ggplot(pennies_sample, aes(x = year)) +
  geom_histogram(binwidth = 10, color = "white")
```

Observe a slightly left-skewed distribution, since most pennies fall between 1980 and 2010 with only a few pennies older than 1970.

```{r}
pennies_sample %>% 
  summarize(mean_year = mean(year))
```

```{r}
pennies_resample <- tibble(
  year = c(1976, 1962, 1976, 1983, 2017, 2015, 2015, 1962, 2016, 1976, 
           2006, 1997, 1988, 2015, 2015, 1988, 2016, 1978, 1979, 1997, 
           1974, 2013, 1978, 2015, 2008, 1982, 1986, 1979, 1981, 2004, 
           2000, 1995, 1999, 2006, 1979, 2015, 1979, 1998, 1981, 2015, 
           2000, 1999, 1988, 2017, 1992, 1997, 1990, 1988, 2006, 2000)
)
```

```{r}
ggplot(pennies_resample, aes(x = year)) +
  geom_histogram(binwidth = 10, color = "white") +
  labs(title = "Resample of 50 pennies")

ggplot(pennies_sample, aes(x = year)) +
  geom_histogram(binwidth = 10, color = "white") +
  labs(title = "Original sample of 50 pennies")
```

Observe in Figure 8.9 that while the general shapes of both distributions of year are roughly similar, they are not identical.

```{r}
pennies_resample %>% 
  summarize(mean_year = mean(year))
```

### Resampling 35 times

```{r}
pennies_resamples
```

```{r}
resampled_means <- pennies_resamples %>% 
  group_by(name) %>% 
  summarize(mean_year = mean(year))
resampled_means
```

```{r}
ggplot(resampled_means, aes(x = mean_year)) +
  geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
  labs(x = "Sampled mean year")
```

Observe in Figure 8.11 that the distribution looks roughly normal and that we rarely observe sample mean years less than 1992 or greater than 2000.
Also observe how the distribution is roughly centered at 1995, which is close to the sample mean of 1995.44 of the original sample of 50 pennies from the bank.

### What did we just do?


## Computer simulation of resampling

### Virtually resampling once

```{r}
virtual_resample <- pennies_sample %>% 
  rep_sample_n(size = 50, replace = TRUE)
```

```{r}
virtual_resample %>% 
  summarize(resample_mean = mean(year))
```

As we saw when we did our tactile resampling exercise, the resulting mean year is different than the mean year of our 50 originally sampled pennies of 1995.44.

### Virtually resampling 35 times

```{r}
virtual_resamples <- pennies_sample %>% 
  rep_sample_n(size = 50, replace = TRUE, reps = 35)
virtual_resamples
```

```{r}
virtual_resampled_means <- virtual_resamples %>% 
  group_by(replicate) %>% 
  summarize(mean_year = mean(year))
virtual_resampled_means
```

```{r}
ggplot(virtual_resampled_means, aes(x = mean_year)) +
  geom_histogram(binwidth = 1, color = "white" ,boundary = 1990) +
  labs(x = "Resample mean year")
```

Bootstrap distributions are constructed by taking multiple resamples from a single sample.
It is an approximation to the sampling distribution.

### Virtually resampling 1000 times

The goals of resampling with replacement is to construct the bootstrap distribution, which is an approximation of the sampling distribution.

```{r}
# Repeat resampling 1000 times
virtual_resamples <- pennies_sample %>% 
  rep_sample_n(size = 50, replace = TRUE, reps = 1000)
```


```{r}
# Compute 1000 sample means
virtual_resampled_means <- virtual_resamples %>% 
  group_by(replicate) %>% 
  summarize(mean_year = mean(year))
```

```{r}
virtual_resampled_means <- pennies_sample %>% 
  rep_sample_n(size = 50, replace = TRUE, reps = 1000) %>% 
  group_by(replicate) %>% 
  summarize(mean_year = mean(year))
virtual_resampled_means
```

```{r}
ggplot(virtual_resampled_means, aes(x = mean_year)) +
  geom_histogram(binwidth = 1, color = "white", boundary = 1990) +
  labs(x = "sample mean")
```

Note here that the bell shape is starting to become much more apparent.
We now have a general sense for the range of values that the sample mean may take on.

```{r}
virtual_resampled_means %>% 
  summarize(mean_of_means = mean(mean_year))
```

The mean of these 1000 means is 1995.49, which is quite close to the mean of our original sample of 50 pennies of 1995.44.
This is the case since each of the 1000 resamples is based on the original sample of 50 pennies.

## Understanding confidence intervals

As opposed to a point estimate/sample statistic that estimates the value of an unknown population parameter with a single value, a confidence interval gives what can be interpreted as a range of plausible values.
Going back to our analogy, point estimates/sample statistics can be thought of as spears, whereas confidence intervals can be thought of as nets.

Higher confidence levels correspond to wider confidence intervals.
Lower confidence levels correspond to narrower confidence intervals.

### Percentile method

One method to construct a confidence interval is to use the middle 95% of values of the bootstrap distribution.
We can do this by computing the 2.5th and 97.5th percentiles, which are 1991.059 and 1999.283, respectively.

### Standard error method

If a numerical variable follows a normal distribution, or, in other words, the histogram of this variable is bell-shaped, then roughly 95% of values fall between $\pm1.96$ standard deviations of the mean.

```{r}
virtual_resampled_means %>% 
  summarize(MEAN = mean(mean_year),
            SE = sd(mean_year))
```

First, the bootstrap distribution has a mean equal to 1995.49.
This value almost coincides exactly with the value of the sample mean $\bar{x}$ of our original 50 pennies of 1995.44.

Second, the bootstrap distribution has a standard deviation equal to 2.074.
The bootstrap distribution is an approximation to the sampling distribution, and the standard deviation of a sampling distribution has a special name: the standard error.

Therefore, we can say that 2.074 is an approximation of the standard error of $\bar{x}$.


## Constructing confidence intervals

### Original workflow

using the rep_sample_n() function and a couple of dplyr verbs to construct the bootstrap distribution

```{r}
pennies_sample %>% 
  rep_sample_n(size = 50, replace = TRUE, reps = 1000) %>% 
  group_by(replicate) %>% 
  summarize(mean_year = mean(year))
```

### infer package workflow

```{r}
pennies_sample %>% 
  summarize(stat = mean(year))
```

```{r}
pennies_sample %>% 
  specify(response = year) %>% 
  calculate(stat = "mean")
```

```{r}
pennies_sample %>% 
  specify(response = year)
```

Notice how the data itself doesn’t change, but the Response: year (numeric) meta-data does. 
This is similar to how the group_by() verb from dplyr doesn’t change the data, but only adds “grouping” meta-data.

```{r}
pennies_sample %>% 
  specify(formula = year ~ NULL)
```

Since in the case of pennies we only have a response variable and no explanatory variable of interest, we set the x on the right-hand side of the ~ to be NULL.

```{r}
pennies_sample %>% 
  specify(response = year) %>% 
  generate(reps = 1000, type = "bootstrap")
```

```{r}
bootstrap_distribution <- pennies_sample %>% 
  specify(response = year) %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "mean")
bootstrap_distribution
```

```{r}
visualize(bootstrap_distribution)
```

```{r}
ggplot(bootstrap_distribution, aes(x = stat)) +
  geom_histogram()
```

### Percentile method with infer

This method sets the lower endpoint of the confidence interval at the 2.5th percentile of the bootstrap distribution and similarly sets the upper endpoint at the 97.5th percentile. 
The resulting interval captures the middle 95% of the values of the sample mean in the bootstrap distribution.

```{r}
percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
```

```{r}
visualize(bootstrap_distribution) + 
  shade_confidence_interval(endpoints = percentile_ci)
```

```{r}
visualize(bootstrap_distribution) + 
  shade_ci(endpoints = percentile_ci, color = "hotpink", fill = "khaki")
```

### Standard error method with infer

For any distribution that is normally shaped, roughly 95% of the values lie within two standard deviations of the mean.

```{r}
x_bar <- 1995.44
```

```{r}
standard_error_ci <- bootstrap_distribution %>% 
  get_confidence_interval(type = "se", point_estimate = x_bar)
standard_error_ci
```

```{r}
visualize(bootstrap_distribution) + 
  shade_confidence_interval(endpoints = standard_error_ci)
```

```{r}
bootstrap_distribution <- pennies_sample %>% 
  specify(response = year) %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "median")

percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
```

```{r}
pennies_sample %>% 
  specify(response = year) %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "median") %>% 
  visualize()

percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
```

## Interpreting confidence intervals

```{r}
bowl %>% 
  summarize(p_red = mean(color == "red"))
```

### Did the net capture the fish?

```{r}
sample_1_bootstrap <- bowl_sample_1 %>% 
  specify(response = color, success = "red") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop")
sample_1_bootstrap
```

```{r}
bowl_sample_1 %>% 
  summarize(mean(color == "red"))
```


```{r}
sample_1_bootstrap %>% 
  summarize(mean(stat))
```


```{r}
percentile_ci_1 <- sample_1_bootstrap %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci_1
```

```{r}
sample_1_bootstrap %>% 
  visualize(bins = 15) + 
  shade_confidence_interval(endpoints = percentile_ci_1) +
  geom_vline(xintercept = 0.375, linetype = "dashed")
```

```{r}
bowl_sample_2 <- bowl %>%
  rep_sample_n(size = 50)
bowl_sample_2
```

```{r}
sample_2_bootstrap <- bowl_sample_2 %>% 
  specify(response = color, success = "red") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop")
sample_2_bootstrap
```

```{r}
percentile_ci_2 <- sample_2_bootstrap %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci_2
```

### Precise and shorthand interpretation

### Width of confidence intervals

## Case study: Is yawning contagious?

### Mythbusters study data

```{r}
mythbusters_yawn
```

```{r}
mythbusters_yawn %>% 
  group_by(group, yawn) %>% 
  summarize(count = n())
```

### Sampling scenario

### Constructing the confidence interval

1. construct the bootstrap distribution for $\hat{p}_{seed}-\hat{p}_{control}$.
2. use this to construct 95% confidence intervals for $p_{seed}-p_{control}$.

```{r}
bootstrap_distribution_yawning <- mythbusters_yawn %>% 
  specify(formula = yawn ~ group, success = "yes") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("seed", "control"))
bootstrap_distribution_yawning
```

```{r}
visualize(bootstrap_distribution_yawning) +
  geom_vline(xintercept = 0)
```

```{r}
bootstrap_distribution_yawning %>% 
  get_confidence_interval(type = "percentile", level = 0.95)
```

```{r}
obs_diff_in_props <- mythbusters_yawn %>% 
  specify(formula = yawn ~ group, success = "yes") %>% 
  # generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("seed", "control"))
obs_diff_in_props
```

```{r}
myth_ci_se <- bootstrap_distribution_yawning %>% 
  get_confidence_interval(type = "se", point_estimate = obs_diff_in_props)
myth_ci_se
```

### Interpreting the confidence interval

we're 95% "confident" that the true difference in proportions $p_{seed}-p_{control}$ is between (-0.238,0.302).
There is one value of particular interest that this 95% confidence interval contains: zero.
If $p_{seed}-p_{control}$ were equal to 0, then there would be no difference in propotion yawning between the two gruops.
This would suggest that there is no associated effect of being exposed to a yawning recruiter on whether you yawn yourself.

In our case, since the 95% confidence interval includes 0, we cannot conclusively say if either proportion is larger. 
Of our 1000 bootstrap resamples with replacement, sometimes $\hat{p}_{seed}$ was higher and thus those exposed to yawning yawned themselves more often.
At other times, the reverse happened.

Say, on the other hand, the 95% confidence interval was entirely above zero. This would suggest that $p_{seed}-p_{control}>0$, or, in other words $p_{seed}>p_{control}$, and thus we'd have evidence suggesting those exposed to yawning do yawn more often.

## Conclusion

### Comparing bootstrap and sampling distributions

We'll compare:

1. the sampling distribution of $\hat{p}$ based on 1000 vritual samples from the bowl (population).
2. the bootstrap distribution of $\hat{p}$ based on 1000 virtual resamples with replacement from a single sample.

#### Sampling distribution

```{r}
# Take 1000 virtual samples of size 50 from the bowl:
virtual_samples <- bowl %>% 
  rep_sample_n(size = 50, reps = 1000)

# Compute the sampling distribution of 1000 values of p-hat
sampling_distribution <- virtual_samples %>% 
  group_by(replicate) %>% 
  summarize(red = sum(color == "red")) %>% 
  mutate(prop_red = red / 50)

# Visualize sampling distribution of p-hat
ggplot(sampling_distribution, aes(x = prop_red)) +
  geom_histogram(binwidth = 0.05, boundary = 0.4, color = "white") +
  labs(x = "Proportion of 50 balls that were red", 
       title = "Sampling distribution")
```

```{r}
sampling_distribution %>% summarize(se = sd(prop_red))
```

#### Bootstrap distribution

```{r}
bootstrap_distribution <- bowl_sample_1 %>% 
  specify(response = color, success = "red") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop")

visualize(bootstrap_distribution)
```

```{r}
bootstrap_distribution %>% summarize(se = sd(stat))
```

#### Comparison

First, observe how the sampling distribution is centered at $p=0.375$.
This is because the sampling is done at random and in an unbiased fashion.
So the estimates $\hat{p}$ are centered at the true value of $p$.

The bootstrap distribution is centered at 0.42, which is the proportion red of Ilyas and Yohan’s 50 sampled balls.
This is because we are resampling from the same sample over and over again. 
Since the bootstrap distribution is centered at the original sample’s proportion, it doesn’t necessarily provide a better estimate of $p=0.375$.
This leads us to our first lesson about bootstrapping:

> The bootstrap distribution will likely not have the same center as the sampling distribution. 
In other words, bootstrapping cannot improve the quality of an estimate.

Second, let’s now compare the spread of the two distributions: they are somewhat similar.
Notice that the bootstrap distribution’s standard error is a rather good approximation to the sampling distribution’s standard error. 
This leads us to our second lesson about bootstrapping:

> Even if the bootstrap distribution might not have the same center as the sampling distribution, it will likely have very similar shape and spread.
In other words, bootstrapping will give you a good estimate of the standard error.

Thus, using the fact that the bootstrap distribution and sampling distributions have similar spreads, we can build confidence intervals using bootstrapping as we’ve done all throughout this chapter!

### Theory-based confidence intervals

```{r}
tactile_prop_red %>% 
  rename(p_hat = prop_red) %>% 
  mutate(
    n = 50,
    SE = sqrt(p_hat * (1 - p_hat) / n),
    MoE = 1.96 * SE,
    lower_ci = p_hat - MoE,
    upper_ci = p_hat + MoE
  )
```

