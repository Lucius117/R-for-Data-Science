---
title: "Statistical Learning"
author: "Xiaochi"
date: "02/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(raster)
library(mlr)
library(dplyr)
library(parallelMap)
```

```{r}
data("landslides", package = "RSAGA")
```

```{r}
class(landslides)
```

```{r}
summary(landslides)
```

```{r}
# select non-landslide points
non_pts = filter(landslides, lslpts == FALSE)
# select landslide points
lsl_pts = filter(landslides, lslpts == TRUE)
# randomly select 175 non-landslide points
set.seed(11042018)
non_pts_sub = sample_n(non_pts, size = nrow(lsl_pts))
# create smaller landslide dataset (lsl)
lsl = bind_rows(non_pts_sub, lsl_pts)
```

```{r}
dem = raster(
  dem$data, 
  crs = dem$header$proj4string,
  xmn = dem$header$xllcorner, 
  xmx = dem$header$xllcorner + dem$header$ncols * dem$header$cellsize,
  ymn = dem$header$yllcorner,
  ymx = dem$header$yllcorner + dem$header$nrows * dem$header$cellsize
  )

plot(dem)
```

```{r}
# attach landslide points with terrain attributes
data("lsl", package = "spDataLarge")
# attach terrain attribute raster stack
data("ta", package = "spDataLarge")
```

```{r}
lsl
```

```{r}
ta
```

# Conventional modeling approach in R

```{r}
fit = glm(lslpts ~ slope + cplan + cprof + elev + log10_carea,
          family = binomial(),
          data = lsl)

class(fit)
summary(fit)
```

```{r}
pred_glm = predict(object = fit, type = "response")
head(pred_glm)
```

```{r}
# making the prediction
pred = raster::predict(ta, model = fit, type = "response")
plot(pred)
```

```{r}
roc <- pROC::roc(lsl$lslpts, fitted(fit))
plot(roc)
```

```{r}
pROC::auc(pROC::roc(lsl$lslpts, fitted(fit)))
```

# Introduction to (spatial) cross-validation

# Spatial CV with mlr

## Generalized linear model

```{r}
library(mlr)
# coordinates needed for the spatial partitioning
coords = lsl[, c("x", "y")]
# select response and predictors to use in the modeling
data = dplyr::select(lsl, -x, -y)
# create task
task = makeClassifTask(data = data, 
                       target = "lslpts",
                       # indicate the landslide initiation point
                       positive = "TRUE", 
                       # for spatial CV
                       coordinates = coords
                       )

getTaskFormula(task)
```

```{r}
listLearners(task, warn.missing.packages = FALSE) %>%
  dplyr::select(class, name, short.name, package)
```

```{r}
lrn = makeLearner(
  # classification method
  cl = "classif.binomial",
  # specify the link-function
  link = "logit",
  # predicted probability
  predict.type = "prob",
  fix.factors.prediction = TRUE)

getLearnerPackages(lrn)
# helpLearner(lrn)
```

```{r}
perf_level = makeResampleDesc(
  method = "SpRepCV", 
  folds = 5, 
  reps = 100)

set.seed(012348)
sp_cv = mlr::resample(
  # specified learner
  learner = lrn,
  # task
  task = task,
  # resampling strategy
  resampling = perf_level, 
  # performance measure
  measures = mlr::auc)
```

```{r}
# summary statistics of the 500 models
summary(sp_cv$measures.test$auc)

# mean AUROC of the 500 models
mean(sp_cv$measures.test$auc)
```

## Spatial tuning of machine-learning hyperparameters

```{r}
library(mlr)
# coordinates needed for the spatial partitioning
coords = lsl[, c("x", "y")]
# select response and predictors to use in the modeling
data = dplyr::select(lsl, -x, -y)
# create task
task = makeClassifTask(data = data, 
                       target = "lslpts",
                       # indicate the landslide initiation point
                       positive = "TRUE", 
                       # for spatial CV
                       coordinates = coords
                       )
```

```{r}
lrns = listLearners(task, warn.missing.packages = TRUE)
filter(lrns, grepl("svm", class)) %>% 
  dplyr::select(class, name, short.name, package)
```

```{r}
lrn_ksvm = makeLearner(
  cl = "classif.ksvm",
  predict.type = "prob",
  kernel = "rbfdot")
```

```{r}
# performance estimation level
perf_level = makeResampleDesc(method = "SpRepCV", folds = 5, reps = 100)
```

```{r}
# five spatially disjoint partitions
tune_level = makeResampleDesc("SpCV", iters = 5)
# use 50 randomly selected hyperparameters
ctrl = makeTuneControlRandom(maxit = 50)
# define the outer limits of the randomly selected hyperparameters
ps = makeParamSet(
  makeNumericParam("C", lower = -12, upper = 15, trafo = function(x) 2^x),
  makeNumericParam("sigma", lower = -15, upper = 6, trafo = function(x) 2^x)
  )
```

```{r}
wrapped_lrn_ksvm = makeTuneWrapper(learner = lrn_ksvm, 
                                   resampling = tune_level,
                                   par.set = ps,
                                   control = ctrl, 
                                   show.info = TRUE,
                                   measures = mlr::auc)
```

```{r}
configureMlr(on.learner.error = "warn", on.error.dump = TRUE)
```

```{r}
library(parallelMap)
if (Sys.info()["sysname"] %in% c("Linux", "Darwin")) {
parallelStart(mode = "multicore", 
              # parallelize the hyperparameter tuning level
              level = "mlr.tuneParams", 
              # just use half of the available cores
              cpus = round(parallel::detectCores() / 2),
              mc.set.seed = TRUE)
}

if (Sys.info()["sysname"] == "Windows") {
  parallelStartSocket(level = "mlr.tuneParams",
                      cpus =  round(parallel::detectCores() / 2))
}

# ?parallelGetRegisteredLevels
```

```{r}
set.seed(12345)
result = mlr::resample(learner = wrapped_lrn_ksvm, 
                       task = task,
                       resampling = perf_level,
                       extract = getTuneResult,
                       measures = mlr::auc)
# stop parallelization
parallelStop()
```

```{r}
result = readRDS("extdata/spatial_cv_result.rds")
```

