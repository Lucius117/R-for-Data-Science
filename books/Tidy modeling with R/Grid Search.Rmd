---
title: "Grid search"
author: "Xiaochi"
date: "18/05/2021"
output: 
    html_document:
      df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, paged.print = FALSE)
library(tidyverse)
library(tidymodels)
tidymodels_prefer()
```

## REGULAR AND NON-REGULAR GRIDS

```{r}
mlp_spec <- 
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
  set_engine("nnet", trace = 0) %>% 
  set_mode("classification")
mlp_spec
```

```{r}
mlp_param <- extract_parameter_set_dials(mlp_spec)
mlp_param
```

```{r}
mlp_param %>% extract_parameter_dials("hidden_units")
mlp_param %>% extract_parameter_dials("penalty")
mlp_param %>% extract_parameter_dials("epochs")
```



### REGULAR GRIDS

```{r}
crossing(
  hidden_units = 1:3,
  penalty = c(0.0, 0.1),
  epochs = c(100, 200)
)
```



```{r}
mlp_param %>% 
  grid_regular(levels = 2)

mlp_param %>% 
  grid_regular(levels = c(hidden_units = 3, penalty = 2, epochs = 2))
```




### IRREGULAR GRIDS



```{r}
set.seed(1301)
mlp_param %>% 
  grid_random(size = 1000) # 'size' is the number of combinations
```

```{r}
set.seed(1301)
mlp_param %>% 
  grid_random(size = 1000) %>% # 'size' is the number of combinations
  summary()
```



```{r}
library(ggforce)
set.seed(1302)

mlp_param %>% 
  # The 'original = FALSE' option keeps penalty in log10 units
  grid_random(size = 20, original = FALSE) %>% 
  ggplot(aes(x = .panel_x, y = .panel_y)) + 
  geom_point() +
  geom_blank() +
  facet_matrix(vars(hidden_units, penalty, epochs), layer.diag = 2) + 
  labs(title = "Random design with 20 candidates")
```



```{r}
set.seed(1303)
mlp_param %>% 
  grid_latin_hypercube(size = 20, original = FALSE) %>% 
  ggplot(aes(x = .panel_x, y = .panel_y)) + 
  geom_point() +
  geom_blank() +
  facet_matrix(vars(hidden_units, penalty, epochs), layer.diag = 2) + 
  labs(title = "Latin Hypercube design with 20 candidates")
```


## EVALUATING THE GRID


```{r}
library(tidymodels)
data(cells)
cells %>% 
  select(-case) -> cells
cells
```


```{r}
set.seed(1304)
cell_folds <- vfold_cv(cells)
cell_folds
```


```{r}
mlp_spec <- 
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
  set_engine("nnet", trace = 0) %>% 
  set_mode("classification")

mlp_rec <-
  recipe(class ~ ., data = cells) %>%
  step_YeoJohnson(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = tune()) %>% 
  step_normalize(all_numeric_predictors())


mlp_wflow <- 
  workflow() %>% 
  add_model(mlp_spec) %>% 
  add_recipe(mlp_rec)
```




```{r}
mlp_param <- 
  mlp_wflow %>% 
  extract_parameter_set_dials() %>% 
    update(
    epochs = epochs(c(50, 200)),
    num_comp = num_comp(c(0, 40))
  )
mlp_param
```

```{r}
mlp_param %>%
  grid_regular(levels = 3)
```



```{r paged.print=FALSE}
roc_res <- metric_set(roc_auc)

set.seed(1305)
mlp_reg_tune <-
  mlp_wflow %>%
  tune_grid(
    cell_folds,
    grid = mlp_param %>% grid_regular(levels = 3),
    metrics = roc_res
  )
mlp_reg_tune
```

```{r fig.width=5, fig.height=4}
autoplot(mlp_reg_tune) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top")
```

```{r}
show_best(mlp_reg_tune) %>% select(-.estimator)
```





```{r}
set.seed(1306)

mlp_sfd_tune <-
  mlp_wflow %>%
  tune_grid(
    cell_folds,
    grid = 20,
    # Pass in the parameter object to use the appropriate range: 
    param_info = mlp_param,
    metrics = roc_res
  )
mlp_sfd_tune
```

```{r}
autoplot(mlp_sfd_tune)
```

```{r}
show_best(mlp_sfd_tune) %>% select(-.estimator)
```








## FINALIZING THE MODEL


```{r}
show_best(mlp_reg_tune, n = 20) %>% select(-.estimator)
```

```{r}
select_best(mlp_reg_tune, metric = "roc_auc")
```


```{r fig.width=5, fig.height=4}
autoplot(mlp_reg_tune) + 
  scale_color_viridis_d(direction = -1) + 
  theme(legend.position = "top")
```

```{r}
logistic_param <- 
  tibble(
    num_comp = 0,
    epochs = 125,
    hidden_units = 1,
    penalty = 1
  )

final_mlp_wflow <- 
  mlp_wflow %>% 
  finalize_workflow(logistic_param)
final_mlp_wflow
```

```{r}
final_mlp_fit <- 
  final_mlp_wflow %>% 
  fit(cells)
```



## TOOLS FOR CREATING TUNING SPECIFICATIONS





```{r}
library(usemodels)

use_xgboost(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + Latitude + Longitude, 
            data = ames_train,
            # Add comments explaining some of the code:
            verbose = TRUE)
```




## TOOLS FOR EFFICIENT GRID SEARCH

```{r}
library(tidymodels)
data(cells)
cells %>% 
  select(-case) -> cells
cells
```


```{r}
set.seed(1304)
cell_folds <- vfold_cv(cells)
cell_folds
```




```{r}
mlp_spec <- 
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
  set_engine("nnet", trace = 0) %>% 
  set_mode("classification")

mlp_rec <-
  recipe(class ~ ., data = cells) %>%
  step_YeoJohnson(all_numeric_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = tune()) %>% 
  step_normalize(all_numeric_predictors())


mlp_wflow <- 
  workflow() %>% 
  add_model(mlp_spec) %>% 
  add_recipe(mlp_rec)

mlp_param <- 
  mlp_wflow %>% 
  extract_parameter_set_dials() %>% 
    update(
    epochs = epochs(c(50, 200)),
    num_comp = num_comp(c(0, 40))
  )
mlp_param
```


```{r}
roc_res <- metric_set(roc_auc)
```




### SUBMODEL OPTIMIZATION


```{r}
c5_spec <- 
  boost_tree(trees = tune()) %>% 
  set_engine("C5.0") %>% 
  set_mode("classification")

set.seed(1307)
c5_spec %>%
  tune_grid(
    class ~ .,
    resamples = cell_folds,
    grid = data.frame(trees = 1:100),
    metrics = roc_res
  )
```



### PARALLEL PROCESSING




### BENCHMARKING BOOSTED TREES





### ACCESS TO GLOBAL VARIABLES


```{r}
coef_penalty <- 0.1
```


```{r}
spec <- linear_reg(penalty = coef_penalty) %>% set_engine("glmnet")
spec$args$penalty
```


```{r}
spec <- linear_reg(penalty = !!coef_penalty) %>% set_engine("glmnet")
spec$args$penalty
```


```{r}
mcmc_args <- list(chains = 3, iter = 1000, cores = 3)
linear_reg() %>% set_engine("stan", !!!mcmc_args)
```


```{r}
library(stringr)
ch_2_vars <- str_subset(names(cells), "ch_2")
ch_2_vars
```



```{r}
# Still uses a reference to global data (~_~;)
recipe(class ~ ., data = cells) %>% 
  step_spatialsign(all_of(ch_2_vars))
```


```{r}
# Inserts the values into the step ヽ(•‿•)ノ
recipe(class ~ ., data = cells) %>% 
  step_spatialsign(!!!ch_2_vars)
```



### RACING METHODS




```{r}
library(finetune)

set.seed(1308)
mlp_sfd_race <-
  mlp_wflow %>%
  tune_race_anova(
    cell_folds,
    grid = 20, # 20 parameter combinations, 20 models
    param_info = mlp_param,
    metrics = roc_res,
    control = control_race(verbose_elim = TRUE)
  )
mlp_sfd_race
```

```{r}
show_best(mlp_sfd_race, n = 10)
```



## CHAPTER SUMMARY